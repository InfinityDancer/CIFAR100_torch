{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d536d1-9dfe-41bf-a506-3990e4f437a0",
      "metadata": {
        "id": "58d536d1-9dfe-41bf-a506-3990e4f437a0",
        "outputId": "ab04be83-8d57-414a-fd4e-91edbf0fa0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# GPU available?\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
        "print(f'using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db12833a-0336-4113-bfd0-38a2424a2902",
      "metadata": {
        "id": "db12833a-0336-4113-bfd0-38a2424a2902"
      },
      "outputs": [],
      "source": [
        "train_dir = r\"C:\\Users\\user\\Documents\\DLab\\cifar10_train\"\n",
        "test_dir = r\"C:\\Users\\user\\Documents\\DLab\\cifar10_test\"\n",
        "\n",
        "# data normalization and augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform = transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform = transform)\n",
        "\n",
        "# create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 64,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 64,\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9780abe2-0170-4ed4-8c4d-354f243e07fb",
      "metadata": {
        "id": "9780abe2-0170-4ed4-8c4d-354f243e07fb"
      },
      "outputs": [],
      "source": [
        "# vanilla CNN\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size= 3, stride = 1, padding = 1) #conv layer 1\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0) # pool\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1) # conv layer 2\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128) # fully connected layer\n",
        "        self.fc2 = nn.Linear(128, 256) # fully connected layer -- another\n",
        "        self.fc3 = nn.Linear(256, 10) # output layer - 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x))) # Conv1 --> ReLU --> Pool\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x))) # Conv2 --> ReLU --> Pool\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x) # Output layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be5ed66-39b3-4fd0-8da2-e14f9b44299d",
      "metadata": {
        "id": "0be5ed66-39b3-4fd0-8da2-e14f9b44299d"
      },
      "outputs": [],
      "source": [
        "# initialising the model, loss function, optimiser\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc3c0e3-7e84-4918-81a6-43e27950af1f",
      "metadata": {
        "id": "afc3c0e3-7e84-4918-81a6-43e27950af1f"
      },
      "outputs": [],
      "source": [
        "# training the model\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        # move data to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], loss: {running_loss/len(train_loader): .4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b520250a-1307-46aa-bee8-d84c13091d0a",
      "metadata": {
        "id": "b520250a-1307-46aa-bee8-d84c13091d0a"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        val_acc = evaluate(model, val_loader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e841f765-b5c8-44dd-9c89-c7247913c61a",
      "metadata": {
        "id": "e841f765-b5c8-44dd-9c89-c7247913c61a"
      },
      "outputs": [],
      "source": [
        "# evaluating on the test set\n",
        "\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        # move data to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct/total\n",
        "print(f\"Test accuracy: {test_accuracy: .2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b040b82-22fc-418b-8594-9b0e6084bd75",
      "metadata": {
        "id": "8b040b82-22fc-418b-8594-9b0e6084bd75"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
